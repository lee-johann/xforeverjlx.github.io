<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>

<div class="publications">
<ol class="bibliography">

<li>
<div class="pub-row">
  <div class="pub-header">
    <div class="pub-image">
      <img src="/assets/img/phantom_wiki.png" class="teaser img-fluid z-depth-1">
      <abbr class="badge">ICML</abbr>
    </div>
    <div class="pub-content">
      <div class="title"><a href="https://arxiv.org/pdf/2502.20377">PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation</a></div>
      <div class="periodical"><em>International Conference on Machine Learning <strong>(ICML)</strong>, 2025</em></div>
      <div class="periodical"><em>ICLR Workshop on Data Problems for Foundation Models, 2025</em></div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2502.20377" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
        <a href="https://github.com/kilian-group/phantom-wiki" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
        <a href="https://huggingface.co/collections/kilian-group/phantomwiki-6783616aa71d66c36c3ecdaa" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Dataset</a>
      </div>
    </div>
  </div>
  <div class="pub-abstract">
    <p>Evaluation datasets and knowledge often get scraped into LLM pretraining data, causing data-contamination. We adresses this with PhantomWiki, a pipeline for generating synthetic datasets (for reasoning and retrieval evaluation). We show its resilience to scraping, and use it to identify 3 areas of improvement in state-of-the-art RAG and agentic methods: subtask composition, multi-branch reasoning, and needle-in-a-haystack style in-context retrieval.</p>
  </div>
</div>
</li>
  
<br>


<li>
<div class="pub-row">
  <div class="pub-header">
    <div class="pub-image">
      <img src="/assets/img/grace.png" class="teaser img-fluid z-depth-1">
    </div>
    <div class="pub-content">
      <div class="title"><a href="https://ojs.stanford.edu/ojs/index.php/grace/article/view/3839/1814">Towards Safe and Ethical AI</a></div>
      <div class="periodical"><em>Stanford GRACE Journal Vol. 3 No. 1 (2025): Generative AI and Global Futures</em></div>
      <div class="periodical">Top 0.5% of 3000+ submissions</div>
      <div class="links">
        <a href="https://ojs.stanford.edu/ojs/index.php/grace/article/view/3839/1814" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      </div>
    </div>
  </div>
  <div class="pub-abstract">
    <p>Since initiatives for  measuring  safe,  ethical  AI are scattered and fragmented, this review outlines state-of-the-art methods, their proper utilization, and systemic weaknesses and scaling issues. By doing so, this review seeks to foster continuing discourse and innovation among both technical developers and non-technical policymakers.</p>
  </div>
</div>
</li>

</ol>
</div>
